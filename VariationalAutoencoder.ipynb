{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaf9c0f-59bc-4779-8dce-34841e179adf",
   "metadata": {},
   "source": [
    "# Simple Variational Autoencoders (VAEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9009b-0bf5-46c0-a771-471f8353ff5f",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Variational_autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5bd62-9f41-49df-ac01-a8bea7d62ab8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note It only works with numpy<2 then tensorflow has to be <2.18 \n",
    "!pip install tensorflow==2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9f56b4-3899-44a5-979e-c82f9cb6152f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e284f2b-0164-4b3d-aea9-caa95b583656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7702f-9d6f-455d-8c24-60aa5a98906a",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01a1138-6e7e-49b1-915a-124c78513e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = self.encoder(input_dim)\n",
    "        self.decoder = self.decoder(input_dim, latent_dim)\n",
    "    \n",
    "    def encoder(self, input_dim):\n",
    "        encoder_inputs = tf.keras.Input(shape=(input_dim,))\n",
    "        x = layers.Dense(8, activation='relu')(encoder_inputs)\n",
    "        x = layers.Dense(12, activation='relu')(x)\n",
    "        z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "        z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "        encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name=\"encoder\")\n",
    "        return encoder\n",
    "\n",
    "    # Define the decoder\n",
    "    def decoder(self, input_dim, latent_dim):\n",
    "        latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "        x = layers.Dense(12, activation='relu')(latent_inputs)\n",
    "        x = layers.Dense(8, activation='relu')(x)\n",
    "        decoder_outputs = layers.Dense(input_dim, activation='sigmoid')(x)\n",
    "        decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "        return decoder\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var = self.encoder(data)\n",
    "            z = self.sampling((z_mean, z_log_var))\n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= data.shape[1]\n",
    "            \n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = -0.5 * tf.reduce_mean(kl_loss)\n",
    "            \n",
    "            # Add penalty for deviation from sum-to-1 on topics\n",
    "            normalization_loss = tf.reduce_mean(\n",
    "                tf.square(tf.reduce_sum(reconstruction[2:4], axis=1) - 1.0)\n",
    "            )\n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss + 1 * normalization_loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        z_mean, z_log_var = self.encoder(data)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(1 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3d36b-72bc-48c9-b3ba-9821a00c2563",
   "metadata": {},
   "source": [
    "## The implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686be4cf-06ea-4e8d-ac45-3c543da2f473",
   "metadata": {},
   "source": [
    "### Train with fake generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c0c89-0e0e-47ae-a23f-77d1de2e89d0",
   "metadata": {},
   "source": [
    "Note that the data are vectors. Each agent will be described by a single vector such as:\n",
    "- [frequency_of_posting, probability of engagement, topic_preference_music, topic_preference_sports]\n",
    "- [0.5, 0.2, 0.7, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7491218-1f01-45b0-bb31-a4607d42ee13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (800, 4)\n",
      "Test data shape: (200, 4)\n",
      "[[0.62 0.46 0.7  0.3 ]\n",
      " [0.22 0.66 0.58 0.42]\n",
      " [0.68 0.64 0.73 0.27]\n",
      " ...\n",
      " [0.32 0.66 0.73 0.27]\n",
      " [0.55 0.38 0.52 0.48]\n",
      " [0.42 0.91 0.58 0.42]]\n"
     ]
    }
   ],
   "source": [
    "input_dim = 4\n",
    "latent_dim = 2\n",
    "\n",
    "data = np.random.rand(1000, input_dim)\n",
    "#generate biases\n",
    "data[:, 3] += 0.5\n",
    "data[:, 2] += 1.0\n",
    "data[:, 1] *= 1\n",
    "data[:, 0] *= 0.8\n",
    "\n",
    "# Normalize only columns 3 and 4 so their sum equals 1\n",
    "sum_cols_34 = np.sum(data[:, 2:4], axis=1, keepdims=True)\n",
    "data[:, 2:4] = data[:, 2:4] / sum_cols_34\n",
    "rounded_data = np.round(data, 2)\n",
    "\n",
    "X_train, X_test = train_test_split(rounded_data, test_size=0.2, random_state=42)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07aa57a9-f05f-4339-832c-6acc0443fea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 0.2409 - loss: 3.2450 - reconstruction_loss: 3.0040\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.1631 - loss: 3.1104 - reconstruction_loss: 2.9474\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.1072 - loss: 2.9826 - reconstruction_loss: 2.8753\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.0720 - loss: 2.9196 - reconstruction_loss: 2.8476\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0489 - loss: 2.8734 - reconstruction_loss: 2.8245\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0335 - loss: 2.8357 - reconstruction_loss: 2.8022\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0243 - loss: 2.8098 - reconstruction_loss: 2.7854\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0178 - loss: 2.7959 - reconstruction_loss: 2.7781\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0137 - loss: 2.7787 - reconstruction_loss: 2.7651\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - kl_loss: 0.0106 - loss: 2.7709 - reconstruction_loss: 2.7604\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0086 - loss: 2.7696 - reconstruction_loss: 2.7610\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0072 - loss: 2.7582 - reconstruction_loss: 2.7510\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0061 - loss: 2.7553 - reconstruction_loss: 2.7492\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - kl_loss: 0.0054 - loss: 2.7495 - reconstruction_loss: 2.7441\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0049 - loss: 2.7489 - reconstruction_loss: 2.7440\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0046 - loss: 2.7442 - reconstruction_loss: 2.7395\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - kl_loss: 0.0044 - loss: 2.7426 - reconstruction_loss: 2.7382\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0042 - loss: 2.7387 - reconstruction_loss: 2.7345\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0038 - loss: 2.7363 - reconstruction_loss: 2.7325\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - kl_loss: 0.0036 - loss: 2.7333 - reconstruction_loss: 2.7297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f881365b7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(input_dim, latent_dim)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(data, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30e6da-cf99-448c-9618-8631f2a2170f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate New Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d0f3ad-b737-4f64-879d-13323b0e9fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "[[0.45 0.5  0.51 0.59]\n",
      " [0.29 0.46 0.78 0.46]\n",
      " [0.39 0.52 0.59 0.47]\n",
      " [0.38 0.51 0.6  0.5 ]\n",
      " [0.4  0.5  0.59 0.5 ]\n",
      " [0.37 0.5  0.61 0.55]\n",
      " [0.28 0.58 0.61 0.58]\n",
      " [0.29 0.5  0.71 0.48]\n",
      " [0.42 0.51 0.57 0.46]\n",
      " [0.42 0.49 0.57 0.55]]\n"
     ]
    }
   ],
   "source": [
    "# Sample 10 random vectors\n",
    "z_sample = np.random.normal(scale = 2, size=(10, latent_dim))\n",
    "# Decode the vectors\n",
    "x_decoded = vae.decoder.predict(z_sample)\n",
    "print(np.round(x_decoded, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
